{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b8ab1f",
   "metadata": {},
   "source": [
    "Clustering \n",
    "\n",
    "steps:\n",
    "\n",
    "    1) selecting cluster centers.\n",
    "    2) computing distance btwn data points to cluster centers, or brtween each cluster center.\n",
    "    3) redefing cluster center based on the resulting distances.\n",
    "    4) repeating the process unti the optimal clusters are reached.\n",
    "    \n",
    "    \n",
    "   steps\n",
    "   \n",
    "       load data\n",
    "       data cleaning \n",
    "       preprocessing pandas\n",
    "       split data into training and testing dataset\n",
    "       train multiple clustering algorithms\n",
    "       evaluate the machine learning model\n",
    "   \n",
    " Algorithms\n",
    " \n",
    "     1)K -Means\n",
    "     takes k clusters and group the data points with low distances\n",
    "\n",
    "   steps\n",
    "\n",
    "     start\n",
    "     k no.of cluster\n",
    "     centroid\n",
    "     calulate distance\n",
    "     grouping with nearest data points\n",
    "         if object is there:\n",
    "         repeat centroid\n",
    "         else:\n",
    "         end\n",
    "         \n",
    " KNN Algoritm\n",
    " \n",
    " classification and cluster algo\n",
    " \n",
    " \n",
    "\n",
    "     \n",
    "     \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699b40c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "9\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "15\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "#Prime Numbers\n",
    "end =20\n",
    "for number in range(2,end+1):\n",
    "  if number > 1:\n",
    "    for i in range(2,number):\n",
    "        if (number%i)==0:\n",
    "            break\n",
    "        else:\n",
    "            print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52e2189a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
      "0  15624510    Male   19            19000          0\n",
      "1  15810944    Male   35            20000          0\n",
      "2  15668575  Female   26            43000          0\n",
      "3  15603246  Female   27            57000          0\n",
      "4  15804002    Male   19            76000          0\n",
      "[0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1]\n",
      "[[64  4]\n",
      " [ 3 29]]\n"
     ]
    }
   ],
   "source": [
    "# importing libraries  \n",
    "import numpy as nm  \n",
    "import matplotlib.pyplot as mtp  \n",
    "import pandas as pd  \n",
    "  \n",
    "#importing datasets  \n",
    "data_set= pd.read_csv('C:\\\\Users\\\\Lenovo\\\\Downloads\\\\Randomex.csv') \n",
    "print(data_set.head()) \n",
    "  \n",
    "#Extracting Independent and dependent Variable  \n",
    "x= data_set.iloc[:, [2,3]].values  \n",
    "y= data_set.iloc[:, 4].values  \n",
    "# Splitting the dataset into training and test set.  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.25, random_state=0)  \n",
    "  \n",
    "#feature Scaling  \n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "st_x= StandardScaler()    \n",
    "x_train= st_x.fit_transform(x_train)    \n",
    "x_test= st_x.transform(x_test)  \n",
    "#Fitting K-NN classifier to the training set  \n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "clasif= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )  \n",
    "clasif.fit(x_train, y_train) \n",
    "#Predicting the test set result  \n",
    "y_pred= clasif.predict(x_test)  \n",
    "print(y_pred)\n",
    "#Creating the Confusion matrix  \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "cm= confusion_matrix(y_test, y_pred)  \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c964b788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: click in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c205075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb99ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "string =\"This is forest of death by james gopal\"\n",
    "tknz_str = sent_tokenize(string)\n",
    "word_str = word_tokenize(string)\n",
    "print(tknz_str)\n",
    "print(word_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d742c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "eng = stopwords.words(\"english\")\n",
    "print(eng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55229249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
